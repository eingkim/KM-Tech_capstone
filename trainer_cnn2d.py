# -*- coding: utf-8 -*-
"""trainer_CNN2D.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gH9WeSleXroYR3adTOZRYJi_y5z6RpYa
"""

import numpy as np
from tensorflow.keras import layers, models
import tensorflow as tf
from google.colab import files
from sklearn.model_selection import train_test_split
"""
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    try:
        # Currently, memory growth needs to be the same across GPUs
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        logical_gpus = tf.config.experimental.list_logical_devices('GPU')
        print(len(gpus), "Physical GPUs,", len(logical_gpus), "Logical GPUs")
    except RuntimeError as e:
        # Memory growth must be set before GPUs have been initialized
        print(e)
"""
#files.upload()
#files.upload()
data = np.load('./data.npy')
labels = np.load('./label (1).npy')
print(data)
batch = 1755
judging_data = 10
features = 43

data = data.reshape((batch, judging_data, features, 1))
labels = labels.reshape((batch, 1))

# data /= 10000 # 이미 정규화

train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size = 0.2, random_state = 712)
train_data = train_data.reshape((train_data.shape[0], judging_data, features, 1))
test_data = test_data.reshape((test_data.shape[0], judging_data, features, 1))

"""
np.random.seed(42)
train_index = np.random.choice(len(data),int(len(data)*0.8),replace=False)
train_data = data[train_index]
train_labels = labels[train_index]
test_index = np.setdiff1d(np.arange(len(data)),train_index)
test_data = data[test_index]
test_labels = labels[test_index]
"""

#print(train_data)
#print(train_index)
#print(train_labels)
#print(labels)
#print(data.shape)
model = models.Sequential()
model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(judging_data, features, 1), padding="same"))
model.add(layers.MaxPool2D((2, 2)))
model.add(layers.Conv2D(32, (3, 3), activation='relu', padding="same"))
model.add(layers.MaxPool2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu', padding="same"))
model.add(layers.MaxPool2D((1, 1)))
model.add(layers.Conv2D(64, (3, 3), activation='relu', padding="same"))
model.add(layers.MaxPool2D((2, 2)))
model.add(layers.Conv2D(128, (3, 3), activation='relu', padding="same"))

model.add(layers.MaxPool2D((1, 1)))
model.add(layers.Conv2D(128, (3, 3), activation='relu', padding="same"))
model.add(layers.MaxPool2D((1, 1)))
model.add(layers.Conv2D(32, (3, 3), activation='relu', padding="same"))
model.add(layers.MaxPool2D((1, 1)))
model.add(layers.Conv2D(64, (3, 3), activation='relu', padding="same"))
#model.add(layers.MaxPool2D((1, 1)))
#model.add(layers.Conv2D(32, (2, 2), activation='relu', padding="same"))
#model.add(layers.AvgPool2D(2))
#model.add(layers.Conv2D(8, 1, activation='relu'))


model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(32, activation='relu'))
model.add(layers.Dense(1, activation='sigmoid'))
model.summary()

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

cp_callback = tf.keras.callbacks.ModelCheckpoint(
    filepath="cp-{epoch:04d}.ckpt", 
    verbose=1, 
    save_weights_only=True,
    period=100)

model.fit(train_data, train_labels, epochs=1000, callbacks=[cp_callback], batch_size=32)

test_loss, test_acc = model.evaluate(test_data,  test_labels, verbose=2)

print(test_acc)

model.save('CNN2D_model.h5')

"""# 새 섹션"""

